<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Method Overview · NonSmoothFwdAD</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../index.html">NonSmoothFwdAD</a></span></div><form class="docs-search" action="../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../index.html">Introduction</a></li><li><span class="tocitem">GeneralizedDiff</span><ul><li class="is-active"><a class="tocitem" href="methodOverview.html">Method Overview</a><ul class="internal"><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="implementationOverview.html">Implementation Overview</a></li><li><a class="tocitem" href="functions.html">Exported Functions</a></li></ul></li><li><span class="tocitem">ConvexOptimization</span><ul><li><a class="tocitem" href="../convexOptimization/implementationOverview.html">Implementation Overview</a></li><li><a class="tocitem" href="../convexOptimization/functions.html">Exported Functions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">GeneralizedDiff</a></li><li class="is-active"><a href="methodOverview.html">Method Overview</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="methodOverview.html">Method Overview</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kamilkhanlab/nonsmooth-forward-ad/blob/main/docs/src/generalizedDiff/methodOverview.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Method-Overview"><a class="docs-heading-anchor" href="#Method-Overview">Method Overview</a><a id="Method-Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Method-Overview" title="Permalink"></a></h1><p>The standard vector forward mode of automatic differentiation (AD) evaluates derivative-matrix products efficiently for composite smooth functions, and is described by Griewank and Walther (2008). For a composite smooth function <strong>f</strong> of <em>n</em> variables, and with derivative <strong>Df</strong>, the vector forward AD mode takes a domain vector <strong>x</strong> and a matrix <strong>M</strong> as input, and produces the product <strong>Df(x) M</strong> as output. To do this, the method regards <strong>f</strong> as a composition of simple elemental functions (such as the arithmetic operations <code>+</code>/<code>-</code>/<code>*</code>/<code>/</code> and trigonometric functions), and handles each elemental function using the standard chain rule for differentiation.</p><p>For nonsmooth functions, this becomes more complicated. While generalized derivatives such as Clarke&#39;s generalized Jacobian are well-defined for continuous functions that are not differentiable everywhere, they have traditionally been considered difficult to evaluate for composite nonsmooth functions, due to failure of classical chain rules. We expect a &quot;correct&quot; generalized derivative to be the actual derivative/gradient when an ostensibly nonsmooth function is in fact smooth, and to be an actual subgradient when the function is convex. Naive extensions of AD to nonsmooth functions, however, do not have these properties.</p><p>Khan and Barton (2012, 2013, 2015) showed that the vector forward AD mode can be generalized to handle composite nonsmooth functions, by defining additional calculus rules for elemental nonsmooth functions such as <code>abs</code>, <code>min</code>, <code>max</code>, and the Euclidean norm. These calculus rules are based on a new construction called the &quot;LD-derivative&quot;, which is a variant of an earlier construction by Nesterov (2005). The resulting &quot;derivative&quot; in the output derivative-matrix product is a valid generalized derivative for use in methods for nonsmooth optimization and equation-solving, with essentially the same properties as an element of Clarke&#39;s generalized Jacobian. In particular:</p><ul><li>if the function is smooth, then this method will compute the actual derivative,</li><li>if the function is convex, then a subgradient will be computed, </li><li>if no multivariate Euclidean norms are present, then an element of Clarke&#39;s generalized Jacobian will be computed,</li><li>in all cases, an element of Nesterov&#39;s lexicographic derivative will be computed.</li></ul><p>Khan and Barton&#39;s nonsmooth vector forward AD mode is also a generalization of a directional derivative evaluation method by Griewank (1994); Griewank&#39;s method is recovered when the chosen matrix <strong>M</strong> has only one column. See Barton et al. (2017) for further discussion of applications and extensions of the nonsmooth vector forward AD mode. </p><p>Khan and Yuan (2020) showed that, for bivariate scalar-valued functions that are locally Lipschitz continuous and directionally differentiable, valid generalized derivatives may be constructed by assembling four directional derivative evaluations into a so-called &quot;compass difference&quot;, without the LD-derivative calculus required in the nonsmooth vector forward AD mode. </p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ul><li>KA Khan and PI Barton, <a href="https://doi.org/10.1080/10556788.2015.1025400">A vector forward mode of automatic differentiation for generalized derivative evaluation</a>, <em>Optimization Methods and Software</em>, 30(6):1185-1212, 2015. DOI:10.1080/10556788.2015.1025400</li><li>KA Khan and Y Yuan, <a href="https://doi.org/10.46298/jnsao-2020-6061">Constructing a subgradient from directional derivatives for functions of two variables</a>, <em>Journal of Nonsmooth Analysis and Optimization</em>, 1:6551, 2020. DOI:10.46298/jnsao-2020-6061</li><li>PI Barton, KA Khan, P Stechlinski, and HAJ Watson, <a href="http://dx.doi.org/10.1080/10556788.2017.1374385">Computationally relevant generalized derivatives: theory, evaluation, and applications</a>, <em>Optimization Methods and Software</em>, 33:1030-1072, 2017. DOI:10.1080/10556788.2017.1374385</li><li>A Griewank, Automatic directional differentiation of nonsmooth composite functions, French-German Conference on Optimization, Dijon, 1994.</li><li>A Griewank and A Walther, Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation (2nd ed.), SIAM, 2008.</li><li>Y Nesterov, Lexicographic differentiation of nonsmooth functions, <em>Mathematical Programming</em>, 104:669-700, 2005.</li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../index.html">« Introduction</a><a class="docs-footer-nextpage" href="implementationOverview.html">Implementation Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 9 April 2023 14:27">Sunday 9 April 2023</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
