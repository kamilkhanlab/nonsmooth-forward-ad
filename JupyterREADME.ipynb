{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63885b7e-3e42-4e22-961f-27f6b94bb207",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Run the following kernel to import all necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d343527-954f-49a0-8409-53df6329ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../nonsmooth-forward-ad/src/NonsmoothFwdAD.jl\")\n",
    "\n",
    "using .NonsmoothFwdAD\n",
    "using .GeneralizedDiff\n",
    "using .ConvexOptimization\n",
    "\n",
    "using JuMP, Ipopt, LinearAlgebra, NLopt, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87afa4-81ed-4d78-8421-1f492b5c7cbe",
   "metadata": {},
   "source": [
    "The usage of `NonSmoothFwdAD` is demonstrated by scripts [test.jl](test/test.jl) and [convexTest.jl](test/convexTest.jl). \n",
    "\n",
    "#### GeneralizedDiff\n",
    "\n",
    "Consider the following nonsmooth function of two variables, to replicate Example 6.2 from Khan and Barton (2013):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab8b1c69-face-451f-ae3c-3504b799174c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = max(min(x[1], -x[2]), x[2] - x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234c4f3d-3408-431e-9e3c-7070189f009b",
   "metadata": {},
   "source": [
    "Using the `NonsmoothFwdAD` module (after `include(\"NonsmoothFwdAD.jl\")` and using `.NonsmoothFwdAD`, `.GeneralizedDiff`), we may evaluate a value `y` and a generalized gradient element `yGrad` of `f` at `[0.0, 0.0]` by the following alternative approaches, using the nonsmooth vector forward mode of AD.\n",
    "\n",
    "- By defining f beforehand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7e70f0d-03e1-4fd8-a44b-74af20eb6488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, [0.0, -1.0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = max(min(x[1], -x[2]), x[2] - x[1])\n",
    "y, yGrad = eval_gen_gradient(f, [0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0770766-b769-47c8-8f05-027ab94769bb",
   "metadata": {},
   "source": [
    "- By defining f as an anonymous function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3fab5ba-0107-42d3-8422-ba2d1559e8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, [0.0, -1.0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, yGrad = eval_gen_gradient([0.0, 0.0]) do x\n",
    "    return max(min(x[1], -x[2]), x[2] - x[1])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca10d1c-016e-4d53-9905-0a3fda8bcc6c",
   "metadata": {},
   "source": [
    "Here, `eval_gen_gradient` constructs `yGrad` as a `Vector{Float64}`, and only applies to scalar-valued functions. For vector-valued functions, `eval_gen_derivative` instead produces a generalized derivative element `yDeriv::Matrix{Float64}`.\n",
    "\n",
    "For scalar-valued functions of one or two variables, the \"compass difference\" is guaranteed to be an element of Clarke's generalized gradient. We may calculate the compass difference `yCompass::Vector{Float64}` for the above function `f` at `[0.0, 0.0]` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cb440ea-ab9d-4768-b679-0169e929d670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, [-0.5, 0.5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, yCompass = eval_compass_difference([0.0, 0.0]) do x\n",
    "    return max(min(x[1], -x[2]), x[2] - x[1])\n",
    "end\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fd299-dd1f-40f1-a02b-255ba2702443",
   "metadata": {},
   "source": [
    "#### ConvexOptimization\n",
    "\n",
    "Consider the following optimization problem, replicating Example 6 in F. Facchinei et. al (2014): \n",
    "\n",
    "```\n",
    "min PHI(x) = (x[1] + x[2])*x[4] + 0.5*(x[2] + x[3])^2 \n",
    "    s.t.    x[1] <= 0\n",
    "            x[2] >= 1\n",
    "            x[4] >= 0\n",
    "            x[1] + x[2] + x[3] >=0 \n",
    "```\n",
    "\n",
    "The provided non-smooth reformulation to the Karush-Kuhn-Tucker system is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c06696-c266-4002-9465-cbb1d83d7f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uOffset = 4\n",
    "vOffset = 9\n",
    "f(x) = [x[4] + x[1+uOffset] - x[2+uOffset] - x[5+uOffset],\n",
    "    x[4] + x[2] + x[3] - x[3+uOffset] - x[5+uOffset],\n",
    "    x[2] + x[3] - x[5+uOffset],\n",
    "    x[1] + x[2] - x[4+uOffset],\n",
    "    x[1] + x[1+vOffset],\n",
    "    - x[1] + x[2+vOffset],\n",
    "    1.0 - x[2] + x[3+vOffset],\n",
    "    - x[4] + x[4+vOffset],\n",
    "    - x[1] - x[2] - x[3] + x[5+vOffset],\n",
    "    min(x[1+uOffset], x[1+vOffset]),\n",
    "    min(x[2+uOffset], x[2+vOffset]),\n",
    "    min(x[3+uOffset], x[3+vOffset]),\n",
    "    min(x[4+uOffset], x[4+vOffset]),\n",
    "    min(x[5+uOffset], x[5+vOffset])] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64775465-6f00-4087-938e-59e892fad16d",
   "metadata": {},
   "source": [
    "Using the `NonsmoothFwdAD` module (after `include(\"NonsmoothFwdAD.jl\")` and using `.NonsmoothFwdAD`, `.GeneralizedDiff`, `.ConvexOptimization`), the LPNewton method can locate the minima of `(x, PHI(x))` by solving `f(x) = 0` given no other binding set constraints. Assume an initial guess of `x0` for `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "144b05ed-094f-4e5e-a57d-b55166cd9bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0014446680056120448, 3.3190935752354815, -3.3176488093686807, -0.00036358277451839, 2.757540039718657, 2.756452152663851, 0.00017972646636453716, 3.3205442397394664, 0.0007223824920200793, -0.0007223339801287438, 0.0007223339799435811, 2.319087744047366, -0.00018199877686866619, 0.0036118164076717465], [1.921788267500533e-6, 0.00017907413389771755, 0.0007223833747807885, -5.996498372962122e-6, 0.000722334025483301, -0.0007223340256684637, -5.8311881154793355e-6, 0.00018158399764972382, 0.000722382535258941, -0.0007223339801287438, 0.0007223339799435811, 0.00017972646636453716, -0.00018199877686866619, 0.0007223824920200793], 4.992764842277354)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = [1.0, 4.0, -2.0, 1.0,\n",
    "    3.0, 3.0, 1.0, 4.0, 1.0,\n",
    "    0.0, 1.0, 3.0, 1.0, 3.0]\n",
    "x, _, gamma = LPNewton(f, x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e251a3-ad2a-4f9d-917a-ed760a7407e2",
   "metadata": {},
   "source": [
    "Thus, the solution for `PHI(x)` is `(x = [0.0, 3.32, -3.32, 0.0], PHI(x) = 0.0)`. \n",
    "\n",
    "Note that the solution set of the optimization problem `PHI(x)` is `X = {(0, t, −t, 0)|t ≥ 1}`. Different initial guesses `x0` could produce different local optima for `PHI(x)` where `f(x) = 0`. This is just one potential solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8ad1c-8f93-4043-b82f-2306f3f34cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
